import requests
import re
import random
import time
import logging
import socket
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
import pytz
import jdatetime
import timeit
import json

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Ù„ÛŒØ³Øª User-Agent Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ HTTP
USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'
]

def get_random_user_agent():
    return random.choice(USER_AGENTS)

def check_proxy_status(server, port, timeout=3):
    """Ú†Ú© Ú©Ø±Ø¯Ù† ÙˆØ¶Ø¹ÛŒØª Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¨Ø§ Ø§ØªØµØ§Ù„ Ø³ÙˆÚ©Øª"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((server, int(port)))
        sock.close()
        if result == 0:
            logging.info(f"Proxy {server}:{port} is online")
            return True
        else:
            logging.warning(f"Proxy {server}:{port} is offline or unreachable")
            return False
    except (socket.timeout, socket.gaierror, ConnectionRefusedError) as e:
        logging.error(f"Error checking proxy {server}:{port}: {e}")
        return False

def measure_proxy_ping(server, port, timeout=3, tries=1):
    """Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒÙ†Ú¯ Ù¾Ø±ÙˆÚ©Ø³ÛŒ (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ø§ØªØµØ§Ù„ Ø¯Ø± Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡)"""
    total_time = 0
    successful_tries = 0
    for _ in range(tries):
        start_time = timeit.default_timer()
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(timeout)
            result = sock.connect_ex((server, int(port)))
            sock.close()
            if result == 0:
                elapsed = (timeit.default_timer() - start_time) * 1000  # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡
                total_time += elapsed
                successful_tries += 1
                logging.debug(f"Ping for {server}:{port}: {elapsed:.2f}ms")
            else:
                logging.warning(f"Ping failed for {server}:{port}")
        except (socket.timeout, socket.gaierror, ConnectionRefusedError) as e:
            logging.error(f"Ping error for {server}:{port}: {e}")
        time.sleep(0.1)  # ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† ØªÙ„Ø§Ø´â€ŒÙ‡Ø§
    if successful_tries > 0:
        average_ping = total_time / successful_tries
        logging.info(f"Average ping for {server}:{port}: {average_ping:.2f}ms")
        return average_ping
    return None

def fetch_proxies_from_url(url, proxy_type, max_proxies=50):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø§Ø² Ù„ÛŒÙ†Ú© Ù…ØªÙ†ÛŒ ÛŒØ§ JSON Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² MTProto"""
    proxies = []
    headers = {'User-Agent': get_random_user_agent()}
    pattern_ip_port = r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5}$'  # ÙØ±Ù…Øª IP:PORT
    pattern_mtproto = r'^tg://proxy\?server=([^&]+)&port=(\d+)&secret=([^\s]+)$'  # ÙØ±Ù…Øª MTProto
    
    try:
        logging.info(f"Fetching {proxy_type} proxies from {url}")
        response = requests.get(url, headers=headers, timeout=20)  # Ø§ÙØ²Ø§ÛŒØ´ Ø²Ù…Ø§Ù†â€ŒØ§ÙˆØª
        response.raise_for_status()
        proxy_checks = []
        
        if proxy_type == 'MTPROTO':
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ MTProto
            lines = response.text.splitlines()
            for line in lines[:max_proxies]:
                line = line.strip()
                if not line:
                    continue
                # ØªØ¨Ø¯ÛŒÙ„ https://t.me/proxy Ø¨Ù‡ tg://proxy Ø¨Ø±Ø§ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ
                line = line.replace('https://t.me/proxy', 'tg://proxy')
                match = re.match(pattern_mtproto, line)
                if match:
                    server, port, secret = match.groups()
                    proxy = f"tg://proxy?server={server}&port={port}&secret={secret}"
                    proxy_checks.append((proxy, server, port))
                else:
                    logging.debug(f"Invalid {proxy_type} proxy format: {line}")
        elif url.endswith('.json'):
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ JSON
            try:
                data = json.loads(response.text)
                if isinstance(data, list):
                    for item in data[:max_proxies]:
                        if 'ip' in item and 'port' in item:
                            server = str(item['ip']).strip()
                            port = str(item['port']).strip()
                            proxy = f"{server}:{port}"
                            if re.match(pattern_ip_port, proxy):
                                proxy_checks.append((proxy, server, port))
                            else:
                                logging.debug(f"Invalid {proxy_type} proxy format in JSON: {proxy}")
                        else:
                            logging.debug(f"Missing ip or port in JSON item: {item}")
                else:
                    logging.error(f"JSON data is not a list: {url}")
            except json.JSONDecodeError as e:
                logging.error(f"Invalid JSON format in {url}: {e}")
        else:
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ Ù…ØªÙ†ÛŒ
            lines = response.text.splitlines()
            for line in lines[:max_proxies]:
                line = line.strip()
                if not line:
                    continue
                if re.match(pattern_ip_port, line):
                    server, port = line.split(':')
                    proxy_checks.append((line, server, port))
                else:
                    logging.debug(f"Invalid {proxy_type} proxy format: {line}")
        
        # Ú†Ú© Ú©Ø±Ø¯Ù† ÙˆØ¶Ø¹ÛŒØª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù¾ÛŒÙ†Ú¯ (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ØºÛŒØ± MTProto)
        if proxy_type != 'MTPROTO':
            with ThreadPoolExecutor(max_workers=20) as executor:  # Ú©Ø§Ù‡Ø´ max_workers
                future_to_proxy = {executor.submit(check_proxy_status, server, port): (proxy, server, port) for proxy, server, port in proxy_checks}
                for future in as_completed(future_to_proxy):
                    proxy, server, port = future_to_proxy[future]
                    try:
                        if future.result():
                            ping = measure_proxy_ping(server, port)
                            if ping is not None:
                                proxies.append((proxy, ping))
                                logging.info(f"Valid and online {proxy_type} proxy: {proxy} (Ping: {ping:.2f}ms)")
                            else:
                                logging.warning(f"Skipping {proxy_type} proxy {proxy} due to ping failure")
                        else:
                            logging.warning(f"Skipping offline {proxy_type} proxy: {proxy}")
                    except Exception as e:
                        logging.error(f"Error checking {proxy_type} proxy {proxy}: {e}")
        else:
            # Ø¨Ø±Ø§ÛŒ MTProto ÙÙ‚Ø· Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø±Ùˆ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… (Ø¨Ø¯ÙˆÙ† Ù¾ÛŒÙ†Ú¯)
            for proxy, server, port in proxy_checks:
                proxies.append((proxy, 0))  # Ù¾ÛŒÙ†Ú¯ ØµÙØ± Ø¨Ø±Ø§ÛŒ MTProto
                logging.info(f"Valid {proxy_type} proxy: {proxy}")
        
        logging.info(f"Fetched {len(proxies)} valid {proxy_type} proxies from {url}")
        if not proxies:
            logging.warning(f"No valid proxies found for {proxy_type} from {url}")
    except requests.RequestException as e:
        logging.error(f"HTTP error fetching {url}: {e}")
    return proxies

def save_proxies_to_file(proxies, proxy_type):
    """Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ ØªÙˆÛŒ Ù¾ÙˆØ´Ù‡ ÙØ¹Ù„ÛŒ"""
    filename = f"./{proxy_type.lower()}.txt"
    try:
        unique_proxies = list(set(proxy[0] for proxy in proxies))
        with open(filename, 'w', encoding='utf-8') as file:
            if unique_proxies:
                for proxy in unique_proxies:
                    file.write(proxy + '\n')
            else:
                file.write('')
                logging.warning(f"No proxies to save for {proxy_type} in {filename}")
        logging.info(f"Saved {len(unique_proxies)} unique {proxy_type} proxies to {filename}")
        if os.path.exists(filename):
            logging.info(f"Confirmed: {filename} exists in the current directory")
        else:
            logging.error(f"Failed: {filename} was not created")
        return proxies
    except IOError as e:
        logging.error(f"Error writing to {filename}: {e}")
        return []

def update_readme(proxy_dict):
    """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ README Ø¨Ø§ Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ¨Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†ÙˆØ¹ Ù¾Ø±ÙˆÚ©Ø³ÛŒ"""
    try:
        utc_now = datetime.now(pytz.UTC)
        iran_tz = pytz.timezone('Asia/Tehran')
        iran_now = utc_now.astimezone(iran_tz)
        jalali_date = jdatetime.datetime.fromgregorian(datetime=iran_now)
        update_time_iran = jalali_date.strftime('%H:%M %d-%m-%Y')
        logging.info(f"Updating README with Iranian timestamp: {update_time_iran}")

        table_rows = ""
        for proxy_type, proxies in proxy_dict.items():
            table_rows += f"\n### ğŸ”— {proxy_type} Proxies\n"
            if proxy_type == 'MTPROTO':
                table_rows += "| # | Ø³Ø±ÙˆØ± (Server) | Ù¾ÙˆØ±Øª (Port) | ÙˆØ¶Ø¹ÛŒØª |\n"
                table_rows += "|---|---------------|-------------|-------|\n"
            else:
                table_rows += "| # | Ø³Ø±ÙˆØ± (Server) | Ù¾ÙˆØ±Øª (Port) | Ù¾ÛŒÙ†Ú¯ (Ping) | ÙˆØ¶Ø¹ÛŒØª |\n"
                table_rows += "|---|---------------|-------------|-------------|-------|\n"
            sample_proxies = random.sample(proxies, min(5, len(proxies))) if proxies else []
            if not sample_proxies:
                table_rows += f"| - | - | - | Ø¨Ø¯ÙˆÙ† Ù¾Ø±ÙˆÚ©Ø³ÛŒ ÙØ¹Ø§Ù„ |\n"
            for i, (proxy, ping) in enumerate(sample_proxies, 1):
                if proxy_type == 'MTPROTO':
                    match = re.match(r'^tg://proxy\?server=([^&]+)&port=(\d+)&secret=([^\s]+)$', proxy)
                    if match:
                        server, port, _ = match.groups()
                        table_rows += f"| {i} | `{server}` | `{port}` | âœ… ÙØ¹Ø§Ù„ |\n"
                else:
                    server, port = proxy.split(':')
                    table_rows += f"| {i} | `{server}` | `{port}` | {ping:.2f}ms | âœ… ÙØ¹Ø§Ù„ |\n"

        readme_content = f"""# ğŸ“Š Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ (Ø¢Ø®Ø±ÛŒÙ† Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ: {update_time_iran})

Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ÛŒÚ© Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù¾Ø§ÛŒØªÙˆÙ† Ø¨Ø±Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ SOCKSØŒ SOCKS5ØŒ SOCKS4ØŒ HTTPS Ùˆ MTPROTO Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…ØªÙ†ÛŒ Ùˆ JSON Ø§Ø³Øª. Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ (`socks.txt`, `socks5.txt`, `socks4.txt`, `https.txt`, `mtproto.txt`) Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.

## âœ¨ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡
Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ SOCKSØŒ SOCKS5ØŒ SOCKS4ØŒ HTTPS Ùˆ MTPROTO Ø±Ø§ Ø§Ø² Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ùˆ JSON (Ù…Ø§Ù†Ù†Ø¯ Ù…Ø®Ø§Ø²Ù† Ú¯ÛŒØªâ€ŒÙ‡Ø§Ø¨) Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ú©Ø±Ø¯Ù‡ Ùˆ Ù¾Ø³ Ø§Ø² Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¢Ù†Ù„Ø§ÛŒÙ† Ø¨ÙˆØ¯Ù† (Ùˆ Ù¾ÛŒÙ†Ú¯ Ø¨Ø±Ø§ÛŒ ØºÛŒØ± MTPROTO)ØŒ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.

## ğŸš€ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
- ğŸŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ø² Ù…Ù†Ø§Ø¨Ø¹ Ù…ØªÙ†ÛŒ Ùˆ JSON
- ğŸ—‘ Ø­Ø°Ù Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
- ğŸ“Š Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù¾ÛŒÙ†Ú¯ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ (Ø¨Ø±Ø§ÛŒ SOCKSØŒ SOCKS5ØŒ SOCKS4ØŒ HTTPS)
- ğŸ“ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù†ÙˆØ¹ Ù¾Ø±ÙˆÚ©Ø³ÛŒ

## ğŸ“‹ Ù¾ÛŒØ´â€ŒÙ†ÛŒØ§Ø²Ù‡Ø§
- ğŸ Ù¾Ø§ÛŒØªÙˆÙ† 3.9
- ğŸ“¦ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: `requests`, `pytz`, `jdatetime`, `json`
- Ù†ØµØ¨ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø§: `pip install -r requirements.txt`

## ğŸ›  Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡
1. ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒ (`socks.txt`, `socks5.txt`, `socks4.txt`, `https.txt`, `mtproto.txt`) Ø±Ø§ Ø§Ø² Ù¾ÙˆØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.
2. Ø§Ø² Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ Ø¯Ø± Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ ÛŒØ§ Ú©Ù„Ø§ÛŒÙ†Øªâ€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯ (Ù…Ø§Ù†Ù†Ø¯ ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø±Ø§ÛŒ MTPROTO) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.

## ğŸŒ Ù…Ù†Ø§Ø¨Ø¹ Ù¾Ø±ÙˆÚ©Ø³ÛŒ
- [openproxylist](https://github.com/roosterkid/openproxylist)
- [KangProxy](https://github.com/officialputuid/KangProxy)
- [Proxifly](https://github.com/proxifly/free-proxy-list)
- [hookzof/socks5_list](https://github.com/hookzof/socks5_list)
- [TheSpeedX/PROXY-List](https://github.com/TheSpeedX/PROXY-List)
- [fyvri/fresh-proxy-list](https://github.com/fyvri/fresh-proxy-list)
- [jetkai/proxy-list](https://github.com/jetkai/proxy-list)
- [proxyscrape](https://proxyscrape.com)
- [MahsaNetConfigTopic/proxy](https://github.com/MahsaNetConfigTopic/proxy)
- [SoliSpirit/mtproto](https://github.com/SoliSpirit/mtproto)

## ğŸ“ˆ Ù†Ù…ÙˆÙ†Ù‡ Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§
Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ Ø±Ø§ Ø¨Ø§ Ù¾ÛŒÙ†Ú¯ Ø¢Ù†â€ŒÙ‡Ø§ (Ø¨Ø±Ø§ÛŒ ØºÛŒØ± MTPROTO) Ù†Ù…Ø§ÛŒØ´ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯:

{table_rows}

> **ğŸ’¡ Ù†Ú©ØªÙ‡**: Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù„ÛŒØ³Øª Ú©Ø§Ù…Ù„ Ùˆ Ø¨Ù‡â€ŒØ±ÙˆØ²ØŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ·Ù‡ Ø±Ø§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯. Ø¨Ø±Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒØŒ ÙØ§ÛŒÙ„ README Ø±Ø§ Ø¨Ù‡â€ŒØµÙˆØ±Øª Ø¯Ø³ØªÛŒ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†ÛŒØ¯.

## ğŸ“œ Ù„Ø§ÛŒØ³Ù†Ø³
Ø§ÛŒÙ† Ù¾Ø±ÙˆÚ˜Ù‡ ØªØ­Øª [Ù„Ø§ÛŒØ³Ù†Ø³ MIT] Ù…Ù†ØªØ´Ø± Ø´Ø¯Ù‡ Ø§Ø³Øª.
"""

        filename = "./README.md"
        try:
            with open(filename, 'w', encoding='utf-8') as file:
                file.write(readme_content)
            logging.info(f"Successfully updated {filename}")
            if os.path.exists(filename):
                logging.info(f"Confirmed: {filename} exists in the current directory")
            else:
                logging.error(f"Failed: {filename} was not created")
        except Exception as e:
            logging.error(f"Error updating {filename}: {e}")

if __name__ == "__main__":
    proxy_urls = {
        'SOCKS': [
            "https://raw.githubusercontent.com/hookzof/socks5_list/master/tg/socks.json",
            "https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks5.txt",
            "https://raw.githubusercontent.com/TheSpeedX/SOCKS-List/master/socks4.txt",
            "https://raw.githubusercontent.com/fyvri/fresh-proxy-list/main/proxies/socks5.txt",
            "https://raw.githubusercontent.com/jetkai/proxy-list/main/online-proxies/txt/proxies-socks5.txt",
            "https://api.proxyscrape.com/v3/free-proxy-list/get?request=displayproxies&proxytype=socks5"
        ],
        'SOCKS5': [
            "https://raw.githubusercontent.com/roosterkid/openproxylist/main/SOCKS5_RAW.txt",
            "https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/socks5/socks5.txt",
            "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/protocols/socks5/data.txt",
            "https://raw.githubusercontent.com/hookzof/socks5_list/refs/heads/master/proxy.txt"
        ],
        'SOCKS4': [
            "https://raw.githubusercontent.com/roosterkid/openproxylist/main/SOCKS4_RAW.txt",
            "https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/socks4/socks4.txt",
            "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/protocols/socks4/data.txt",
        ],
        'HTTPS': [
            "https://raw.githubusercontent.com/roosterkid/openproxylist/main/HTTPS_RAW.txt",
            "https://raw.githubusercontent.com/officialputuid/KangProxy/KangProxy/https/https.txt",
            "https://cdn.jsdelivr.net/gh/proxifly/free-proxy-list@main/proxies/protocols/http/data.txt",
        ],
        'MTPROTO': [
            "https://raw.githubusercontent.com/MahsaNetConfigTopic/proxy/main/proxies.txt",
            "https://raw.githubusercontent.com/SoliSpirit/mtproto/master/all_proxies.txt"
        ]
    }

    proxy_dict = {}
    for proxy_type, urls in proxy_urls.items():
        all_proxies = []
        for url in urls:
            proxies = fetch_proxies_from_url(url, proxy_type)
            all_proxies.extend(proxies)
        proxy_dict[proxy_type] = all_proxies
        save_proxies_to_file(all_proxies, proxy_type)

    update_readme(proxy_dict)
